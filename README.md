Neurolabs Image Recognition Pipeline & Analytics

This project implements an end-to-end workflow for running image inference using the Neurolabs API, saving per-image results, and performing product-level analytics & visualizations.
It covers the full pipeline:

Fetch tasks

Submit image URLs

Retrieve inference results

Store results locally

Join detections with catalog metadata

Build analytics (pie charts, bar charts, histograms)

Export cleaned datasets & charts

ğŸš€ Project Overview

This repository contains:

A Python backend pipeline (src/)

A complete analysis workflow in Jupyter (notebooks/)

Stored inference results (data/)

Exported analytics (notebooks/outputs/)

Chart generation utilities (chart_generator.py)

It is designed to be clean, modular, and easy to extend.

ğŸ“¦ Features
âœ” Image Recognition Pipeline

Load image URLs from CSV

Submit URLs to Neurolabs /image-recognition/tasks/{uuid}/urls

Retrieve per-image COCO-formatted results

Save each result as JSON

âœ” Data Normalization

Extract bounding boxes, categories, confidence scores

Map COCO category_id â†’ catalog productUuid

Build clean pandas DataFrames

âœ” Catalog Join

Fetch /catalog-items

Join detection results with official product metadata (name, brand, etc.)

âœ” Analytics

Product distribution

Brand distribution

Model confidence statistics

Histogram & bar charts

Output tables and CSV files

âœ” Reporting

All charts saved to notebooks/outputs/charts

Clean merged dataset saved to df_joined.csv

## Project Structure

NEUROLABS/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api_client.py          # API calls to Neurolabs
â”‚   â”œâ”€â”€ pipeline.py            # Full inference pipeline
â”‚   â””â”€â”€ utils.py               # CSV loading, URL cleaning, helpers
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ results_json/          # Raw JSON inference outputs
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ analysis.ipynb         # Main analysis & visualization notebook
â”‚   â”œâ”€â”€ analysis_utils.py      # JSON â†’ DataFrame extraction helpers
â”‚   â”œâ”€â”€ chart_generator.py     # Functions to automatically generate & save charts
â”‚   â””â”€â”€ outputs/
â”‚       â”œâ”€â”€ df_joined.csv
â”‚       â”œâ”€â”€ df_products_only.csv
â”‚       â””â”€â”€ charts/
â”‚           â”œâ”€â”€ top_products.png
â”‚           â”œâ”€â”€ confidence_hist.png
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ .env                       # API key (not committed)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


ğŸ§© Architecture (High-Level Flow)
                        +--------------------------+
                        |  /image-recognition/tasks |
                        +------------+-------------+
                                     |
                         Fetch Task UUIDs
                                     |
                                     v
+--------------------+     +---------------------+
|  image_urls.csv    | --> | Submit URLs to Task |
+--------------------+     +---------------------+
                                     |
                                     v
                        +------------------------------+
                        | Retrieve per-image results   |
                        | /tasks/{uuid}/results/{rid}  |
                        +---------------+--------------+
                                        |
                                Save result JSON files
                                        |
                                        v
                      +-------------------------------+
                      |  Parse JSON â†’ DataFrame       |
                      |  (COCO annotations + catalog) |
                      +-------------------------------+
                                        |
                                        v
                           +----------------------+
                           |   Analytics & Charts |
                           +----------------------+

ğŸ”§ Setup & Installation
1. Clone the repo
git clone <repo-url>
cd neurolabs

2. Create a virtual environment
python3 -m venv .venv
source .venv/bin/activate

3. Install requirements
pip install -r requirements.txt

4. Create .env in project root
NEUROLABS_API_KEY=your_key_here

ğŸ— Running the Inference Pipeline

The inference pipeline fetches tasks, submits images, retrieves detection results, and saves JSON files.

Run:

python src/main.py


This will:

âœ” load URLs
âœ” clean them (removing < >)
âœ” submit them in batches
âœ” save JSON results in data/results_json/...

ğŸ“Š Running Analytics (Jupyter Notebook)

Open:

notebooks/analysis.ipynb

Select Run All Cells

All outputs appear in:

notebooks/outputs/

ğŸ“ˆ Example Outputs
Product Distribution

(saved to outputs/charts/top_products.png)

Confidence Histogram

(saved to outputs/charts/confidence_hist.png)

Brand Pie Chart

(saved to outputs/charts/brand_pie.png)

